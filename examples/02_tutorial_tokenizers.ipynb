{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install toiro[all_tokenizers]\n",
    "from toiro import tokenizers\n",
    "from toiro import datadownloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nagisa': {'is_available': True, 'version': '0.2.7'},\n",
       " 'janome': {'is_available': True, 'version': '0.3.10'},\n",
       " 'mecab-python3': {'is_available': True, 'version': '0.996'},\n",
       " 'sudachipy': {'is_available': True, 'version': '0.4.9'},\n",
       " 'spacy': {'is_available': True, 'version': '2.3.2'},\n",
       " 'ginza': {'is_available': True, 'version': '2.3.2'},\n",
       " 'kytea': {'is_available': True, 'version': '0.1.5'},\n",
       " 'jumanpp': {'is_available': True, 'version': '0.4.1'},\n",
       " 'sentencepiece': {'is_available': True, 'version': '0.1.91'}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A list of available tokenizers in toiro\n",
    "tokenizers.available_tokenizers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toiro includes a sample text file\n",
    "sample_txt = datadownloader.sample_datasets.sample_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 439/439 [00:00<00:00, 22748.66it/s]\n",
      "  0%|          | 0/439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/9] Tokenizer: mecab-python3\n",
      "[2/9] Tokenizer: janome\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 439/439 [00:01<00:00, 273.85it/s]\n",
      "  3%|▎         | 15/439 [00:00<00:03, 124.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/9] Tokenizer: nagisa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 439/439 [00:02<00:00, 160.15it/s]\n",
      "  5%|▌         | 24/439 [00:00<00:01, 238.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/9] Tokenizer: sudachipy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 439/439 [00:01<00:00, 311.88it/s]\n",
      "  5%|▍         | 20/439 [00:00<00:02, 170.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/9] Tokenizer: spacy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 439/439 [00:01<00:00, 251.38it/s]\n",
      "  4%|▍         | 17/439 [00:00<00:02, 167.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6/9] Tokenizer: ginza\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 439/439 [00:01<00:00, 249.01it/s]\n",
      "100%|██████████| 439/439 [00:00<00:00, 7628.06it/s]\n",
      "  5%|▌         | 22/439 [00:00<00:01, 218.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7/9] Tokenizer: kytea\n",
      "[8/9] Tokenizer: jumanpp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 439/439 [00:00<00:00, 603.80it/s]\n",
      "100%|██████████| 439/439 [00:00<00:00, 21842.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9/9] Tokenizer: sentencepiece\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Compare the processing speed of tokenizers\n",
    "report = tokenizers.compare_from_file(sample_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'execution_environment': {'python_version': '3.7.8.final.0 (64 bit)', 'arch': 'X86_64', 'brand_raw': 'Intel(R) Core(TM) i7-7700K CPU @ 4.20GHz', 'count': 8}, 'data': {'number_of_sentences': 439, 'average_length': 81.79043280182232}, 'mecab-python3': {'elapsed_time': 0.019868850708007812}, 'janome': {'elapsed_time': 1.6034212112426758}, 'nagisa': {'elapsed_time': 2.7418212890625}, 'sudachipy': {'elapsed_time': 1.4079265594482422}, 'spacy': {'elapsed_time': 1.7468245029449463}, 'ginza': {'elapsed_time': 1.7634239196777344}, 'kytea': {'elapsed_time': 0.05843210220336914}, 'jumanpp': {'elapsed_time': 0.7275857925415039}, 'sentencepiece': {'elapsed_time': 0.02068305015563965}}\n"
     ]
    }
   ],
   "source": [
    "# Report includes an execution environment, a data, and elapsed time.\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mecab-python3: 都庁|所在地|は|新宿|区|。\n",
      "       janome: 都庁|所在地|は|新宿|区|。\n",
      "       nagisa: 都庁|所在|地|は|新宿|区|。\n",
      "    sudachipy: 都庁|所在地|は|新宿区|。\n",
      "        spacy: 都庁|所在|地|は|新宿|区|。\n",
      "        ginza: 都庁|所在地|は|新宿区|。\n",
      "        kytea: 都庁|所在|地|は|新宿|区|。\n",
      "      jumanpp: 都庁|所在|地|は|新宿|区|。\n",
      "sentencepiece: ▁|都|庁|所在地|は|新宿|区|。\n"
     ]
    }
   ],
   "source": [
    "# Compare the segmented words of tokenizers\n",
    "text = \"都庁所在地は新宿区。\"\n",
    "tokenizers.print_words(text, delimiter=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['都庁', '所在地', 'は', '新宿', '区', '。']\n"
     ]
    }
   ],
   "source": [
    "# The words are tokenized by mecab-python3\n",
    "words = tokenizers.tokenize_mecab(text)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "都庁\t名詞,一般,*,*,*,*,都庁,トチョウ,トチョー\n",
      "所在地\t名詞,一般,*,*,*,*,所在地,ショザイチ,ショザイチ\n",
      "は\t助詞,係助詞,*,*,*,*,は,ハ,ワ\n",
      "新宿\t名詞,固有名詞,地域,一般,*,*,新宿,シンジュク,シンジュク\n",
      "区\t名詞,接尾,地域,*,*,*,区,ク,ク\n",
      "。\t記号,句点,*,*,*,*,。,。,。\n",
      "EOS\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This is the result of the original analysis by mecab-python3.\n",
    "tokens = tokenizers.original_mecab(text)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁', '都', '庁', '所在地', 'は', '新宿', '区', '。']\n"
     ]
    }
   ],
   "source": [
    "# The words are tokenized by sentencepiece\n",
    "words = tokenizers.tokenize_sentencepiece(text)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['▁', '都', '庁', '所在地', 'は', '新宿', '区', '。'], [5, 880, 1410, 5812, 6, 4797, 251, 6723]]\n"
     ]
    }
   ],
   "source": [
    "# This is the result of the original analysis by sentencepiece\n",
    "tokens = tokenizers.original_sentencepiece(text)\n",
    "print(tokens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
